{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the trained model on a random (full) image with normals only (3 channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STONE WALL SEGMENTATION WITH FIXED OVERLAP HANDLING - 3 CHANNEL NORMAL MAP VERSION\n",
    "# ============================================================================\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION SECTION - MODIFY THESE PARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "# === INPUT PATHS ===\n",
    "NORMALS_IMAGE_PATH =\"C:/Users/admin/Desktop/AWS_TRAINING/2025-08-10_4classEX/testing/04_normals/K_Bf_22_DEM_normalmap.png\"\n",
    "MODEL_PATH = \"C:/Users/admin/Documents/GitHub/ancientwallsegmentation/2025-08-11_3-channel_4-class-EX_300.pth\"  # Path to your 3-channel model\n",
    "\n",
    "# === OUTPUT PATH ===\n",
    "OUTPUT_DIR = \"C:/Users/admin/Desktop/AWS_TRAINING/2025-08-10_4classEX/testing/05_outputs/3-channel\"\n",
    "\n",
    "# === WINDOW PARAMETERS - BACK TO ORIGINAL ===\n",
    "MODEL_SIZE = (512, 512)        # Size expected by the model\n",
    "WINDOW_SIZE = (1280, 1280)     # Larger window for context\n",
    "STRIDE = 960                   # 25% overlap\n",
    "\n",
    "# === CLASS CONFIGURATION ===\n",
    "CLASS_NAMES = [\n",
    "    \"Background\",    # Class 0 - Black\n",
    "    \"Ashlar\",       # Class 1 - Blue\n",
    "    \"Polygonal\",    # Class 2 - Red  \n",
    "    \"Quarry\"        # Class 3 - Yellow\n",
    "]\n",
    "\n",
    "CLASS_COLORS = [\n",
    "    [0, 0, 0],      # Black - Background\n",
    "    [0, 0, 255],    # Blue - Ashlar\n",
    "    [255, 0, 0],    # Red - Polygonal\n",
    "    [255, 255, 0]   # Yellow - Quarry\n",
    "]\n",
    "\n",
    "# === OVERLAP HANDLING ===\n",
    "OVERLAP_METHOD = \"center_weighted\"  # Options: \"average\", \"center_weighted\", \"max_confidence\"\n",
    "\n",
    "# === GPU/MEMORY MANAGEMENT ===\n",
    "FALLBACK_TO_CPU = True          # Fallback to CPU if GPU runs out of memory\n",
    "\n",
    "# === VISUALIZATION OPTIONS ===\n",
    "SHOW_PLOTS = True               # Show matplotlib plots\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL DEFINITION (DO NOT MODIFY)\n",
    "# ============================================================================\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"Double convolution block matching TensorFlow's implementation\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=True)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout2d(dropout_rate)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=True)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        return x\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels, dropout_rate)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling exactly like TensorFlow's UpSampling2D + Conv2D\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        self.conv_after_up = nn.Conv2d(in_channels, in_channels // 2, kernel_size=3, padding=1)\n",
    "        self.conv = DoubleConv(in_channels, out_channels, dropout_rate)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        x1 = self.conv_after_up(x1)\n",
    "        \n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        if diffX != 0 or diffY != 0:\n",
    "            x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                            diffY // 2, diffY - diffY // 2])\n",
    "        \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class MultiUNet(nn.Module):\n",
    "    def __init__(self, n_channels=3, n_classes=5):  # Changed default to 3 channels\n",
    "        super(MultiUNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 16, 0.1)\n",
    "        self.down1 = Down(16, 32, 0.1)\n",
    "        self.down2 = Down(32, 64, 0.2)\n",
    "        self.down3 = Down(64, 128, 0.2)\n",
    "        self.down4 = Down(128, 256, 0.3)\n",
    "        \n",
    "        self.up1 = Up(256, 128, 0.2)\n",
    "        self.up2 = Up(128, 64, 0.2)\n",
    "        self.up3 = Up(64, 32, 0.1)\n",
    "        self.up4 = Up(32, 16, 0.1)\n",
    "        self.outc = nn.Conv2d(16, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "# ============================================================================\n",
    "# PROCESSING FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def load_normal_map(normals_path):\n",
    "    \"\"\"Load normal map image (3 channels)\"\"\"\n",
    "    normals = cv2.imread(normals_path, cv2.IMREAD_COLOR)\n",
    "    if normals is None:\n",
    "        raise ValueError(f\"Error loading normal map image: {normals_path}\")\n",
    "    \n",
    "    # Ensure we have exactly 3 channels\n",
    "    if len(normals.shape) == 2:\n",
    "        # Grayscale image, convert to 3 channel\n",
    "        normals = cv2.cvtColor(normals, cv2.COLOR_GRAY2BGR)\n",
    "    elif normals.shape[2] == 4:\n",
    "        # RGBA image, drop alpha channel\n",
    "        normals = normals[:, :, :3]\n",
    "    elif normals.shape[2] != 3:\n",
    "        raise ValueError(f\"Normal map has unexpected number of channels: {normals.shape[2]}\")\n",
    "    \n",
    "    print(f\"Normal map loaded: {normals.shape}\")\n",
    "    return normals\n",
    "\n",
    "def create_sliding_windows(image, window_size, stride):\n",
    "    \"\"\"Create overlapping windows from an image\"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    windows = []\n",
    "    positions = []\n",
    "    \n",
    "    for y in range(0, height, stride):\n",
    "        for x in range(0, width, stride):\n",
    "            y_end = min(y + window_size[0], height)\n",
    "            x_end = min(x + window_size[1], width)\n",
    "            \n",
    "            y_start = max(0, y_end - window_size[0])\n",
    "            x_start = max(0, x_end - window_size[1])\n",
    "            \n",
    "            window = image[y_start:y_end, x_start:x_end]\n",
    "            \n",
    "            if window.shape[0] != window_size[0] or window.shape[1] != window_size[1]:\n",
    "                new_window = np.zeros((window_size[0], window_size[1], image.shape[2]), dtype=image.dtype)\n",
    "                new_window[:window.shape[0], :window.shape[1]] = window\n",
    "                window = new_window\n",
    "                \n",
    "            windows.append(window)\n",
    "            positions.append((y_start, x_start, y_end, x_end))\n",
    "    \n",
    "    return windows, positions\n",
    "\n",
    "def load_segmentation_model(model_path, device):\n",
    "    \"\"\"Load the pre-trained segmentation model\"\"\"\n",
    "    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
    "    \n",
    "    n_classes = checkpoint.get('n_classes', 5)\n",
    "    img_channels = checkpoint.get('img_channels', 3)  # Default to 3 channels\n",
    "    \n",
    "    model = MultiUNet(n_channels=img_channels, n_classes=n_classes)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model, n_classes\n",
    "\n",
    "def segment_window_with_probabilities(model, normals, device='cuda'):\n",
    "    \"\"\"Segment a window using normal map only and return both prediction and probabilities\"\"\"\n",
    "    try:\n",
    "        # Resize normals to model size\n",
    "        normals_resized = cv2.resize(normals, MODEL_SIZE, interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # Normalize to [0, 1]\n",
    "        normals_norm = normals_resized.astype('float32') / 255.0\n",
    "        \n",
    "        # Convert to tensor (3 channels: normal X, Y, Z components)\n",
    "        input_tensor = torch.FloatTensor(normals_norm).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(input_tensor)\n",
    "            # Get probabilities with softmax\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            pred_label = torch.argmax(logits, dim=1)[0].cpu().numpy()\n",
    "            probs_np = probs[0].cpu().numpy()  # Shape: (n_classes, 512, 512)\n",
    "        \n",
    "        if device == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Resize predictions back to window size\n",
    "        pred_label_resized = cv2.resize(pred_label.astype(np.uint8), \n",
    "                                       (WINDOW_SIZE[1], WINDOW_SIZE[0]), \n",
    "                                       interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        # Resize probabilities - use INTER_LINEAR for smooth probabilities\n",
    "        probs_resized = np.zeros((probs_np.shape[0], WINDOW_SIZE[0], WINDOW_SIZE[1]), dtype=np.float32)\n",
    "        for c in range(probs_np.shape[0]):\n",
    "            probs_resized[c] = cv2.resize(probs_np[c], \n",
    "                                         (WINDOW_SIZE[1], WINDOW_SIZE[0]), \n",
    "                                         interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        return pred_label_resized, probs_resized\n",
    "        \n",
    "    except RuntimeError as e:\n",
    "        if \"out of memory\" in str(e) and device == 'cuda' and FALLBACK_TO_CPU:\n",
    "            print(\"GPU out of memory, falling back to CPU...\")\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            model = model.to('cpu')\n",
    "            return segment_window_with_probabilities(model, normals, device='cpu')\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "def combine_predictions_center_weighted(windows_data, positions, original_shape, n_classes):\n",
    "    \"\"\"Combine windows giving more weight to center pixels\"\"\"\n",
    "    height, width = original_shape[:2]\n",
    "    \n",
    "    class_scores = np.zeros((height, width, n_classes), dtype=np.float32)\n",
    "    weights = np.zeros((height, width), dtype=np.float32)\n",
    "    \n",
    "    # Create Gaussian-like weight for each window (center has more weight)\n",
    "    h, w = WINDOW_SIZE\n",
    "    y_coords, x_coords = np.ogrid[:h, :w]\n",
    "    center_y, center_x = h / 2, w / 2\n",
    "    \n",
    "    # Distance from center\n",
    "    dist = np.sqrt((x_coords - center_x)**2 + (y_coords - center_y)**2)\n",
    "    max_dist = np.sqrt(center_x**2 + center_y**2)\n",
    "    \n",
    "    # Weight: 1.0 at center, 0.3 at edges\n",
    "    window_weight = 1.0 - (dist / max_dist) * 0.7\n",
    "    \n",
    "    with tqdm(total=len(windows_data), desc=\"Combining with center weighting\") as pbar:\n",
    "        for (pred, probs), (y_start, x_start, y_end, x_end) in zip(windows_data, positions):\n",
    "            actual_h = y_end - y_start\n",
    "            actual_w = x_end - x_start\n",
    "            \n",
    "            # Apply the weighted probabilities\n",
    "            for c in range(n_classes):\n",
    "                class_scores[y_start:y_end, x_start:x_end, c] += probs[c, :actual_h, :actual_w] * window_weight[:actual_h, :actual_w]\n",
    "            \n",
    "            weights[y_start:y_end, x_start:x_end] += window_weight[:actual_h, :actual_w]\n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Normalize by weights\n",
    "    weights = np.maximum(weights, 1e-6)\n",
    "    class_scores /= np.expand_dims(weights, axis=2)\n",
    "    \n",
    "    # Get final predictions\n",
    "    segmentation = np.argmax(class_scores, axis=2).astype(np.uint8)\n",
    "    \n",
    "    return segmentation, class_scores\n",
    "\n",
    "def simple_cleanup(segmentation):\n",
    "    \"\"\"Simple morphological cleanup without changing stone classifications\"\"\"\n",
    "    cleaned = segmentation.copy()\n",
    "    \n",
    "    # Small median filter to smooth boundaries\n",
    "    cleaned = cv2.medianBlur(cleaned.astype(np.uint8), 3)\n",
    "    \n",
    "    # Remove very small isolated pixels\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    for class_id in range(1, 4):\n",
    "        mask = (cleaned == class_id).astype(np.uint8)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "        cleaned[cleaned == class_id] = 0\n",
    "        cleaned[mask == 1] = class_id\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "def visualize_normal_components(normals):\n",
    "    \"\"\"Create visualization of normal map components\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Convert BGR to RGB for display\n",
    "    normals_rgb = cv2.cvtColor(normals, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Show X component (Red channel in RGB)\n",
    "    axes[0].imshow(normals_rgb[:, :, 0], cmap='RdBu_r')\n",
    "    axes[0].set_title('Normal X Component')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Show Y component (Green channel in RGB)\n",
    "    axes[1].imshow(normals_rgb[:, :, 1], cmap='RdBu_r')\n",
    "    axes[1].set_title('Normal Y Component')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Show Z component (Blue channel in RGB)\n",
    "    axes[2].imshow(normals_rgb[:, :, 2], cmap='Blues')\n",
    "    axes[2].set_title('Normal Z Component')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.suptitle('Normal Map Components Analysis')\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "def run_segmentation():\n",
    "    \"\"\"Main execution function for 3-channel normal map segmentation\"\"\"\n",
    "    \n",
    "    # Setup\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"3-CHANNEL NORMAL MAP SEGMENTATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Extract image name\n",
    "    image_name = os.path.splitext(os.path.basename(NORMALS_IMAGE_PATH))[0]\n",
    "    \n",
    "    # Load normal map\n",
    "    print(\"=== Loading normal map image ===\")\n",
    "    normals = load_normal_map(NORMALS_IMAGE_PATH)\n",
    "    \n",
    "    # Create windows\n",
    "    print(\"=== Creating overlapping windows ===\")\n",
    "    print(f\"Window size: {WINDOW_SIZE}, Stride: {STRIDE}\")\n",
    "    normals_windows, positions = create_sliding_windows(normals, WINDOW_SIZE, STRIDE)\n",
    "    print(f\"Created: {len(normals_windows)} windows\")\n",
    "    \n",
    "    # Load model\n",
    "    print(\"=== Loading 3-channel model ===\")\n",
    "    model, n_classes = load_segmentation_model(MODEL_PATH, device)\n",
    "    print(f\"Model loaded: {n_classes} classes\")\n",
    "    \n",
    "    # Validate class configuration\n",
    "    if n_classes > len(CLASS_NAMES):\n",
    "        print(f\"WARNING: Model has {n_classes} classes, but only {len(CLASS_NAMES)} names defined!\")\n",
    "        for i in range(len(CLASS_NAMES), n_classes):\n",
    "            CLASS_NAMES.append(f\"Class {i}\")\n",
    "            color = cm.get_cmap('tab10')(i / 10)[:3]\n",
    "            CLASS_COLORS.append((np.array(color) * 255).astype(int).tolist())\n",
    "    \n",
    "    # Perform segmentation with probabilities\n",
    "    print(\"=== Performing segmentation ===\")\n",
    "    windows_data = []\n",
    "    \n",
    "    with tqdm(total=len(normals_windows), desc=\"Segmenting windows\") as pbar:\n",
    "        for i in range(len(normals_windows)):\n",
    "            pred, probs = segment_window_with_probabilities(\n",
    "                model, normals_windows[i], device\n",
    "            )\n",
    "            windows_data.append((pred, probs))\n",
    "            pbar.update(1)\n",
    "            \n",
    "            if i % 10 == 0 and device == 'cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    # Combine predictions with center weighting\n",
    "    print(\"=== Combining predictions with center weighting ===\")\n",
    "    full_segmentation, class_scores = combine_predictions_center_weighted(\n",
    "        windows_data, positions, normals.shape, n_classes\n",
    "    )\n",
    "    \n",
    "    # Save raw output\n",
    "    colors = np.array(CLASS_COLORS[:n_classes])\n",
    "    output_raw_path = os.path.join(OUTPUT_DIR, f\"{image_name}_RAW_combined_3ch.png\")\n",
    "    colored_raw = np.zeros((full_segmentation.shape[0], full_segmentation.shape[1], 3), dtype=np.uint8)\n",
    "    for i in range(n_classes):\n",
    "        colored_raw[full_segmentation == i] = colors[i]\n",
    "    colored_raw_bgr = cv2.cvtColor(colored_raw, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(output_raw_path, colored_raw_bgr)\n",
    "    print(f\"RAW combined segmentation saved at: {output_raw_path}\")\n",
    "    \n",
    "    # Apply simple cleanup\n",
    "    print(\"=== Applying simple cleanup ===\")\n",
    "    full_segmentation = simple_cleanup(full_segmentation)\n",
    "    \n",
    "    # Save results\n",
    "    print(\"=== Saving results ===\")\n",
    "    \n",
    "    # Save grayscale segmentation\n",
    "    output_path = os.path.join(OUTPUT_DIR, f\"{image_name}_segmented_3ch.png\")\n",
    "    cv2.imwrite(output_path, full_segmentation)\n",
    "    print(f\"Grayscale segmentation saved at: {output_path}\")\n",
    "    \n",
    "    # Save colored segmentation\n",
    "    colored_segmentation = np.zeros((full_segmentation.shape[0], full_segmentation.shape[1], 3), dtype=np.uint8)\n",
    "    for i in range(n_classes):\n",
    "        colored_segmentation[full_segmentation == i] = colors[i]\n",
    "    \n",
    "    colored_segmentation_bgr = cv2.cvtColor(colored_segmentation, cv2.COLOR_RGB2BGR)\n",
    "    output_colored_path = os.path.join(OUTPUT_DIR, f\"{image_name}_segmented_colored_3ch.png\")\n",
    "    cv2.imwrite(output_colored_path, colored_segmentation_bgr)\n",
    "    print(f\"Colored segmentation saved at: {output_colored_path}\")\n",
    "    \n",
    "    # Save class information\n",
    "    info_path = os.path.join(OUTPUT_DIR, f\"{image_name}_class_info_3ch.txt\")\n",
    "    with open(info_path, 'w') as f:\n",
    "        f.write(\"3-Channel Normal Map Segmentation - Class Information:\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\")\n",
    "        f.write(f\"Input channels: 3 (Normal Map RGB)\\n\")\n",
    "        f.write(f\"Window size: {WINDOW_SIZE}\\n\")\n",
    "        f.write(f\"Model input size: {MODEL_SIZE}\\n\")\n",
    "        f.write(f\"Stride: {STRIDE}\\n\")\n",
    "        f.write(f\"Overlap method: {OVERLAP_METHOD}\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\")\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            pixel_count = np.sum(full_segmentation == i)\n",
    "            percentage = (pixel_count / full_segmentation.size) * 100\n",
    "            f.write(f\"Class {i}: {CLASS_NAMES[i] if i < len(CLASS_NAMES) else f'Class {i}'}\\n\")\n",
    "            f.write(f\"  Color: RGB{tuple(colors[i])}\\n\")\n",
    "            f.write(f\"  Pixels: {pixel_count:,}\\n\")\n",
    "            f.write(f\"  Coverage: {percentage:.2f}%\\n\")\n",
    "    \n",
    "    print(f\"Class information saved at: {info_path}\")\n",
    "    \n",
    "    # Visualization\n",
    "    if SHOW_PLOTS:\n",
    "        print(\"=== Creating visualization ===\")\n",
    "        \n",
    "        # First figure: Normal map components\n",
    "        normal_fig = visualize_normal_components(normals)\n",
    "        plt.show()\n",
    "        \n",
    "        # Second figure: Main results\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        \n",
    "        # Full normal map (RGB visualization)\n",
    "        normals_display = cv2.cvtColor(normals, cv2.COLOR_BGR2RGB)\n",
    "        axes[0].imshow(normals_display)\n",
    "        axes[0].set_title(\"Normal Map (RGB)\")\n",
    "        axes[0].axis(\"off\")\n",
    "        \n",
    "        # Surface angle visualization (derived from Z component)\n",
    "        z_component = normals[:, :, 2].astype(np.float32) / 255.0\n",
    "        angle = np.arccos(np.clip(z_component, 0, 1)) * 180 / np.pi\n",
    "        im_angle = axes[1].imshow(angle, cmap='viridis')\n",
    "        axes[1].set_title(\"Surface Angle (degrees)\")\n",
    "        axes[1].axis(\"off\")\n",
    "        plt.colorbar(im_angle, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "        \n",
    "        # Segmentation result\n",
    "        cmap_seg = ListedColormap([np.array(color)/255.0 for color in CLASS_COLORS[:n_classes]])\n",
    "        im = axes[2].imshow(full_segmentation, cmap=cmap_seg, vmin=0, vmax=n_classes-1)\n",
    "        axes[2].set_title(\"Segmentation Result (3-Channel)\")\n",
    "        axes[2].axis(\"off\")\n",
    "        \n",
    "        # Add colorbar for segmentation\n",
    "        cbar = plt.colorbar(im, ax=axes[2], fraction=0.046, pad=0.04)\n",
    "        cbar.set_ticks(range(n_classes))\n",
    "        cbar.set_ticklabels([CLASS_NAMES[i] if i < len(CLASS_NAMES) else f'Class {i}' for i in range(n_classes)])\n",
    "        \n",
    "        plt.suptitle(\"3-Channel Normal Map Segmentation Results\", fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return full_segmentation, colored_segmentation\n",
    "\n",
    "# ============================================================================\n",
    "# RUN THE SEGMENTATION\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    segmentation_result, colored_result = run_segmentation()\n",
    "    print(\"=== 3-Channel Segmentation complete! ===\")\n",
    "    print(\"This version uses:\")\n",
    "    print(\"- 3-channel normal map input only (no RGB/RGBA)\")\n",
    "    print(\"- Normal map encodes surface geometry (X, Y, Z components)\")\n",
    "    print(\"- Original window size (1280x1280) for proper context\")\n",
    "    print(\"- Center-weighted combination to reduce edge artifacts\")\n",
    "    print(\"- Probability-based merging instead of hard voting\")\n",
    "    print(\"- Minimal post-processing to preserve model predictions\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
