{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the trained model on a random (full) image with ortho and normals (7 channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "=== Loading images ===\n",
      "Images loaded: RGBA (4002, 16126, 4), Normals (4002, 16126, 3)\n",
      "=== Creating overlapping windows ===\n",
      "Window size: (1280, 1280), Stride: 960\n",
      "Created: 85 windows\n",
      "=== Loading model ===\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy._core'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 469\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;66;03m# RUN THE SEGMENTATION\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;66;03m# ============================================================================\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 469\u001b[0m     segmentation_result, colored_result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_segmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== Segmentation complete! ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis version uses:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 346\u001b[0m, in \u001b[0;36mrun_segmentation\u001b[0;34m()\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== Loading model ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 346\u001b[0m model, n_classes \u001b[38;5;241m=\u001b[39m \u001b[43mload_segmentation_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m classes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    349\u001b[0m \u001b[38;5;66;03m# Validate class configuration\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 196\u001b[0m, in \u001b[0;36mload_segmentation_model\u001b[0;34m(model_path, device)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_segmentation_model\u001b[39m(model_path, device):\n\u001b[1;32m    195\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load the pre-trained segmentation model\"\"\"\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m checkpoint\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_classes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m    199\u001b[0m     img_channels \u001b[38;5;241m=\u001b[39m checkpoint\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_channels\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m7\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/serialization.py:1165\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m mod_name \u001b[38;5;241m=\u001b[39m load_module_mapping\u001b[38;5;241m.\u001b[39mget(mod_name, mod_name)\n\u001b[0;32m-> 1165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy._core'"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STONE WALL SEGMENTATION WITH FIXED OVERLAP HANDLING\n",
    "# ============================================================================\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION SECTION - MODIFY THESE PARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "# === INPUT PATHS ===\n",
    "RGBA_IMAGE_PATH =\"C:/Users/admin/Desktop/AWS_TRAINING/2025-08-10_4classEX/testing/03_orthos/Kaunos_Isodom_png-ortho.png\"\n",
    "NORMALS_IMAGE_PATH =\"C:/Users/admin/Desktop/AWS_TRAINING/2025-08-10_4classEX/testing/04_normals/Kauns_Isodom_png-DEM_normalmap.png\"\n",
    "MODEL_PATH = \"C:/Users/admin/Documents/GitHub/ancientwallsegmentation/2025-08-11_7-channel_4-class-EX_300.pth\"\n",
    "\n",
    "# === OUTPUT PATH ===\n",
    "OUTPUT_DIR = \"C:/Users/admin/Desktop/AWS_TRAINING/2025-08-10_4classEX/testing/05_outputs\"\n",
    "\n",
    "# === WINDOW PARAMETERS - BACK TO ORIGINAL ===\n",
    "MODEL_SIZE = (512, 512)        # Size expected by the model\n",
    "WINDOW_SIZE = (1280, 1280)     # Larger window for context\n",
    "STRIDE = 960                   # 25% overlap\n",
    "\n",
    "# === CLASS CONFIGURATION ===\n",
    "CLASS_NAMES = [\n",
    "    \"Background\",    # Class 0 - Black\n",
    "    \"Ashlar\",       # Class 1 - Blue\n",
    "    \"Polygonal\",    # Class 2 - Red  \n",
    "    \"Quarry\"        # Class 3 - Yellow\n",
    "]\n",
    "\n",
    "CLASS_COLORS = [\n",
    "    [0, 0, 0],      # Black - Background\n",
    "    [0, 0, 255],    # Blue - Ashlar\n",
    "    [255, 0, 0],    # Red - Polygonal\n",
    "    [255, 255, 0]   # Yellow - Quarry\n",
    "]\n",
    "\n",
    "# === OVERLAP HANDLING ===\n",
    "OVERLAP_METHOD = \"center_weighted\"  # Options: \"average\", \"center_weighted\", \"max_confidence\"\n",
    "\n",
    "# === GPU/MEMORY MANAGEMENT ===\n",
    "FALLBACK_TO_CPU = True          # Fallback to CPU if GPU runs out of memory\n",
    "\n",
    "# === VISUALIZATION OPTIONS ===\n",
    "SHOW_PLOTS = True               # Show matplotlib plots\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL DEFINITION (DO NOT MODIFY)\n",
    "# ============================================================================\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"Double convolution block matching TensorFlow's implementation\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=True)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout2d(dropout_rate)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=True)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        return x\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels, dropout_rate)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling exactly like TensorFlow's UpSampling2D + Conv2D\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        self.conv_after_up = nn.Conv2d(in_channels, in_channels // 2, kernel_size=3, padding=1)\n",
    "        self.conv = DoubleConv(in_channels, out_channels, dropout_rate)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        x1 = self.conv_after_up(x1)\n",
    "        \n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        if diffX != 0 or diffY != 0:\n",
    "            x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                            diffY // 2, diffY - diffY // 2])\n",
    "        \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class MultiUNet(nn.Module):\n",
    "    def __init__(self, n_channels=7, n_classes=5):\n",
    "        super(MultiUNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 16, 0.1)\n",
    "        self.down1 = Down(16, 32, 0.1)\n",
    "        self.down2 = Down(32, 64, 0.2)\n",
    "        self.down3 = Down(64, 128, 0.2)\n",
    "        self.down4 = Down(128, 256, 0.3)\n",
    "        \n",
    "        self.up1 = Up(256, 128, 0.2)\n",
    "        self.up2 = Up(128, 64, 0.2)\n",
    "        self.up3 = Up(64, 32, 0.1)\n",
    "        self.up4 = Up(32, 16, 0.1)\n",
    "        self.outc = nn.Conv2d(16, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "# ============================================================================\n",
    "# PROCESSING FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def load_images(rgba_path, normals_path):\n",
    "    \"\"\"Load RGBA and normal map images\"\"\"\n",
    "    img_rgba = cv2.imread(rgba_path, cv2.IMREAD_UNCHANGED)\n",
    "    if img_rgba is None:\n",
    "        raise ValueError(f\"Error loading RGBA image: {rgba_path}\")\n",
    "    if img_rgba.shape[2] != 4:\n",
    "        print(f\"WARNING: Image {rgba_path} doesn't have 4 channels, adding alpha channel.\")\n",
    "        alpha = np.ones((img_rgba.shape[0], img_rgba.shape[1], 1), dtype=img_rgba.dtype) * 255\n",
    "        img_rgba = np.concatenate([img_rgba, alpha], axis=2)\n",
    "    \n",
    "    normals = cv2.imread(normals_path, cv2.IMREAD_COLOR)\n",
    "    if normals is None:\n",
    "        raise ValueError(f\"Error loading normals image: {normals_path}\")\n",
    "    \n",
    "    print(f\"Images loaded: RGBA {img_rgba.shape}, Normals {normals.shape}\")\n",
    "    return img_rgba, normals\n",
    "\n",
    "def create_sliding_windows(image, window_size, stride):\n",
    "    \"\"\"Create overlapping windows from an image\"\"\"\n",
    "    height, width = image.shape[:2]\n",
    "    windows = []\n",
    "    positions = []\n",
    "    \n",
    "    for y in range(0, height, stride):\n",
    "        for x in range(0, width, stride):\n",
    "            y_end = min(y + window_size[0], height)\n",
    "            x_end = min(x + window_size[1], width)\n",
    "            \n",
    "            y_start = max(0, y_end - window_size[0])\n",
    "            x_start = max(0, x_end - window_size[1])\n",
    "            \n",
    "            window = image[y_start:y_end, x_start:x_end]\n",
    "            \n",
    "            if window.shape[0] != window_size[0] or window.shape[1] != window_size[1]:\n",
    "                new_window = np.zeros((window_size[0], window_size[1], image.shape[2]), dtype=image.dtype)\n",
    "                new_window[:window.shape[0], :window.shape[1]] = window\n",
    "                window = new_window\n",
    "                \n",
    "            windows.append(window)\n",
    "            positions.append((y_start, x_start, y_end, x_end))\n",
    "    \n",
    "    return windows, positions\n",
    "\n",
    "def load_segmentation_model(model_path, device):\n",
    "    \"\"\"Load the pre-trained segmentation model\"\"\"\n",
    "    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
    "    \n",
    "    n_classes = checkpoint.get('n_classes', 5)\n",
    "    img_channels = checkpoint.get('img_channels', 7)\n",
    "    \n",
    "    model = MultiUNet(n_channels=img_channels, n_classes=n_classes)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model, n_classes\n",
    "\n",
    "def segment_window_with_probabilities(model, rgb, alpha, normals, device='cuda'):\n",
    "    \"\"\"Segment a window and return both prediction and probabilities\"\"\"\n",
    "    try:\n",
    "        rgb_resized = cv2.resize(rgb, MODEL_SIZE, interpolation=cv2.INTER_AREA)\n",
    "        alpha_resized = cv2.resize(alpha, MODEL_SIZE, interpolation=cv2.INTER_AREA)\n",
    "        normals_resized = cv2.resize(normals, MODEL_SIZE, interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        if alpha_resized.ndim == 2:\n",
    "            alpha_resized = np.expand_dims(alpha_resized, axis=2)\n",
    "        \n",
    "        full_img = np.concatenate([rgb_resized, alpha_resized, normals_resized], axis=2)\n",
    "        full_img_norm = full_img.astype('float32') / 255.0\n",
    "        \n",
    "        input_tensor = torch.FloatTensor(full_img_norm).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(input_tensor)\n",
    "            # Get probabilities with softmax\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            pred_label = torch.argmax(logits, dim=1)[0].cpu().numpy()\n",
    "            probs_np = probs[0].cpu().numpy()  # Shape: (n_classes, 512, 512)\n",
    "        \n",
    "        if device == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Resize predictions back to window size\n",
    "        pred_label_resized = cv2.resize(pred_label.astype(np.uint8), \n",
    "                                       (WINDOW_SIZE[1], WINDOW_SIZE[0]), \n",
    "                                       interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        # Resize probabilities - use INTER_LINEAR for smooth probabilities\n",
    "        probs_resized = np.zeros((probs_np.shape[0], WINDOW_SIZE[0], WINDOW_SIZE[1]), dtype=np.float32)\n",
    "        for c in range(probs_np.shape[0]):\n",
    "            probs_resized[c] = cv2.resize(probs_np[c], \n",
    "                                         (WINDOW_SIZE[1], WINDOW_SIZE[0]), \n",
    "                                         interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        return pred_label_resized, probs_resized\n",
    "        \n",
    "    except RuntimeError as e:\n",
    "        if \"out of memory\" in str(e) and device == 'cuda' and FALLBACK_TO_CPU:\n",
    "            print(\"GPU out of memory, falling back to CPU...\")\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            model = model.to('cpu')\n",
    "            return segment_window_with_probabilities(model, rgb, alpha, normals, device='cpu')\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "def combine_predictions_center_weighted(windows_data, positions, original_shape, n_classes):\n",
    "    \"\"\"Combine windows giving more weight to center pixels\"\"\"\n",
    "    height, width = original_shape[:2]\n",
    "    \n",
    "    class_scores = np.zeros((height, width, n_classes), dtype=np.float32)\n",
    "    weights = np.zeros((height, width), dtype=np.float32)\n",
    "    \n",
    "    # Create Gaussian-like weight for each window (center has more weight)\n",
    "    h, w = WINDOW_SIZE\n",
    "    y_coords, x_coords = np.ogrid[:h, :w]\n",
    "    center_y, center_x = h / 2, w / 2\n",
    "    \n",
    "    # Distance from center\n",
    "    dist = np.sqrt((x_coords - center_x)**2 + (y_coords - center_y)**2)\n",
    "    max_dist = np.sqrt(center_x**2 + center_y**2)\n",
    "    \n",
    "    # Weight: 1.0 at center, 0.3 at edges\n",
    "    window_weight = 1.0 - (dist / max_dist) * 0.7\n",
    "    \n",
    "    with tqdm(total=len(windows_data), desc=\"Combining with center weighting\") as pbar:\n",
    "        for (pred, probs), (y_start, x_start, y_end, x_end) in zip(windows_data, positions):\n",
    "            actual_h = y_end - y_start\n",
    "            actual_w = x_end - x_start\n",
    "            \n",
    "            # Apply the weighted probabilities\n",
    "            for c in range(n_classes):\n",
    "                class_scores[y_start:y_end, x_start:x_end, c] += probs[c, :actual_h, :actual_w] * window_weight[:actual_h, :actual_w]\n",
    "            \n",
    "            weights[y_start:y_end, x_start:x_end] += window_weight[:actual_h, :actual_w]\n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Normalize by weights\n",
    "    weights = np.maximum(weights, 1e-6)\n",
    "    class_scores /= np.expand_dims(weights, axis=2)\n",
    "    \n",
    "    # Get final predictions\n",
    "    segmentation = np.argmax(class_scores, axis=2).astype(np.uint8)\n",
    "    \n",
    "    return segmentation, class_scores\n",
    "\n",
    "def simple_cleanup(segmentation):\n",
    "    \"\"\"Simple morphological cleanup without changing stone classifications\"\"\"\n",
    "    cleaned = segmentation.copy()\n",
    "    \n",
    "    # Small median filter to smooth boundaries\n",
    "    cleaned = cv2.medianBlur(cleaned.astype(np.uint8), 3)\n",
    "    \n",
    "    # Remove very small isolated pixels\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    for class_id in range(1, 4):\n",
    "        mask = (cleaned == class_id).astype(np.uint8)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "        cleaned[cleaned == class_id] = 0\n",
    "        cleaned[mask == 1] = class_id\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "def run_segmentation():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    \n",
    "    # Setup\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Extract image name\n",
    "    image_name = os.path.splitext(os.path.basename(RGBA_IMAGE_PATH))[0]\n",
    "    \n",
    "    # Load images\n",
    "    print(\"=== Loading images ===\")\n",
    "    img_rgba, normals = load_images(RGBA_IMAGE_PATH, NORMALS_IMAGE_PATH)\n",
    "    rgb = img_rgba[:, :, :3]\n",
    "    alpha = img_rgba[:, :, 3:]\n",
    "    \n",
    "    # Create windows\n",
    "    print(\"=== Creating overlapping windows ===\")\n",
    "    print(f\"Window size: {WINDOW_SIZE}, Stride: {STRIDE}\")\n",
    "    rgb_windows, positions = create_sliding_windows(rgb, WINDOW_SIZE, STRIDE)\n",
    "    alpha_windows, _ = create_sliding_windows(alpha, WINDOW_SIZE, STRIDE)\n",
    "    normals_windows, _ = create_sliding_windows(normals, WINDOW_SIZE, STRIDE)\n",
    "    print(f\"Created: {len(rgb_windows)} windows\")\n",
    "    \n",
    "    # Load model\n",
    "    print(\"=== Loading model ===\")\n",
    "    model, n_classes = load_segmentation_model(MODEL_PATH, device)\n",
    "    print(f\"Model loaded: {n_classes} classes\")\n",
    "    \n",
    "    # Validate class configuration\n",
    "    if n_classes > len(CLASS_NAMES):\n",
    "        print(f\"WARNING: Model has {n_classes} classes, but only {len(CLASS_NAMES)} names defined!\")\n",
    "        for i in range(len(CLASS_NAMES), n_classes):\n",
    "            CLASS_NAMES.append(f\"Class {i}\")\n",
    "            color = cm.get_cmap('tab10')(i / 10)[:3]\n",
    "            CLASS_COLORS.append((np.array(color) * 255).astype(int).tolist())\n",
    "    \n",
    "    # Perform segmentation with probabilities\n",
    "    print(\"=== Performing segmentation ===\")\n",
    "    windows_data = []\n",
    "    \n",
    "    with tqdm(total=len(rgb_windows), desc=\"Segmenting windows\") as pbar:\n",
    "        for i in range(len(rgb_windows)):\n",
    "            pred, probs = segment_window_with_probabilities(\n",
    "                model, rgb_windows[i], alpha_windows[i], normals_windows[i], device\n",
    "            )\n",
    "            windows_data.append((pred, probs))\n",
    "            pbar.update(1)\n",
    "            \n",
    "            if i % 10 == 0 and device == 'cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    # Combine predictions with center weighting\n",
    "    print(\"=== Combining predictions with center weighting ===\")\n",
    "    full_segmentation, class_scores = combine_predictions_center_weighted(\n",
    "        windows_data, positions, img_rgba.shape, n_classes\n",
    "    )\n",
    "    \n",
    "    # Save raw output\n",
    "    colors = np.array(CLASS_COLORS[:n_classes])\n",
    "    output_raw_path = os.path.join(OUTPUT_DIR, f\"{image_name}_RAW_combined.png\")\n",
    "    colored_raw = np.zeros((full_segmentation.shape[0], full_segmentation.shape[1], 3), dtype=np.uint8)\n",
    "    for i in range(n_classes):\n",
    "        colored_raw[full_segmentation == i] = colors[i]\n",
    "    colored_raw_bgr = cv2.cvtColor(colored_raw, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(output_raw_path, colored_raw_bgr)\n",
    "    print(f\"RAW combined segmentation saved at: {output_raw_path}\")\n",
    "    \n",
    "    # Apply simple cleanup\n",
    "    print(\"=== Applying simple cleanup ===\")\n",
    "    full_segmentation = simple_cleanup(full_segmentation)\n",
    "    \n",
    "    # Save results\n",
    "    print(\"=== Saving results ===\")\n",
    "    \n",
    "    # Save grayscale segmentation\n",
    "    output_path = os.path.join(OUTPUT_DIR, f\"{image_name}_segmented.png\")\n",
    "    cv2.imwrite(output_path, full_segmentation)\n",
    "    print(f\"Grayscale segmentation saved at: {output_path}\")\n",
    "    \n",
    "    # Save colored segmentation\n",
    "    colored_segmentation = np.zeros((full_segmentation.shape[0], full_segmentation.shape[1], 3), dtype=np.uint8)\n",
    "    for i in range(n_classes):\n",
    "        colored_segmentation[full_segmentation == i] = colors[i]\n",
    "    \n",
    "    colored_segmentation_bgr = cv2.cvtColor(colored_segmentation, cv2.COLOR_RGB2BGR)\n",
    "    output_colored_path = os.path.join(OUTPUT_DIR, f\"{image_name}_segmented_colored.png\")\n",
    "    cv2.imwrite(output_colored_path, colored_segmentation_bgr)\n",
    "    print(f\"Colored segmentation saved at: {output_colored_path}\")\n",
    "    \n",
    "    # Save class information\n",
    "    info_path = os.path.join(OUTPUT_DIR, f\"{image_name}_class_info.txt\")\n",
    "    with open(info_path, 'w') as f:\n",
    "        f.write(\"Center-Weighted Segmentation - Class Information:\")\n",
    "        f.write(\"-\" * 50 + \"\")\n",
    "        f.write(f\"Window size: {WINDOW_SIZE}\")\n",
    "        f.write(f\"Model input size: {MODEL_SIZE}\")\n",
    "        f.write(f\"Stride: {STRIDE}\")\n",
    "        f.write(f\"Overlap method: {OVERLAP_METHOD}\")\n",
    "        f.write(\"-\" * 50 + \"\")\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            pixel_count = np.sum(full_segmentation == i)\n",
    "            percentage = (pixel_count / full_segmentation.size) * 100\n",
    "            f.write(f\"Class {i}: {CLASS_NAMES[i] if i < len(CLASS_NAMES) else f'Class {i}'}\")\n",
    "            f.write(f\"  Color: RGB{tuple(colors[i])}\")\n",
    "            f.write(f\"  Pixels: {pixel_count:,}\")\n",
    "            f.write(f\"  Coverage: {percentage:.2f}%\")\n",
    "    \n",
    "    print(f\"Class information saved at: {info_path}\")\n",
    "    \n",
    "    # Visualization\n",
    "    if SHOW_PLOTS:\n",
    "        print(\"=== Creating visualization ===\")\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        \n",
    "        # Original image\n",
    "        rgb_display = cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n",
    "        axes[0].imshow(rgb_display)\n",
    "        axes[0].set_title(\"Original Image\")\n",
    "        axes[0].axis(\"off\")\n",
    "        \n",
    "        # Normal map\n",
    "        normals_display = cv2.cvtColor(normals, cv2.COLOR_BGR2RGB)\n",
    "        axes[1].imshow(normals_display)\n",
    "        axes[1].set_title(\"Normal Map\")\n",
    "        axes[1].axis(\"off\")\n",
    "        \n",
    "        # Segmentation result\n",
    "        cmap_seg = ListedColormap([np.array(color)/255.0 for color in CLASS_COLORS[:n_classes]])\n",
    "        im = axes[2].imshow(full_segmentation, cmap=cmap_seg, vmin=0, vmax=n_classes-1)\n",
    "        axes[2].set_title(\"Segmentation Result\")\n",
    "        axes[2].axis(\"off\")\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(im, ax=axes[2], fraction=0.046, pad=0.04)\n",
    "        cbar.set_ticks(range(n_classes))\n",
    "        cbar.set_ticklabels([CLASS_NAMES[i] if i < len(CLASS_NAMES) else f'Class {i}' for i in range(n_classes)])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return full_segmentation, colored_segmentation\n",
    "\n",
    "# ============================================================================\n",
    "# RUN THE SEGMENTATION\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    segmentation_result, colored_result = run_segmentation()\n",
    "    print(\"=== Segmentation complete! ===\")\n",
    "    print(\"This version uses:\")\n",
    "    print(\"- Original window size (1280x1280) for proper context\")\n",
    "    print(\"- Center-weighted combination to reduce edge artifacts\")\n",
    "    print(\"- Probability-based merging instead of hard voting\")\n",
    "    print(\"- Minimal post-processing to preserve model predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Visualization for Paper Figure\n",
    "\n",
    "This section addresses the reviewer's comment (Line 417) about demonstrating the \"subjective\" character of manual interpretation vs. machine segmentation.\n",
    "\n",
    "**Key difference:**\n",
    "- **Manual classification:** Each region gets a single categorical label (effectively 100% confidence)\n",
    "- **ML segmentation:** Each pixel receives a probability distribution across all classes\n",
    "\n",
    "The code below visualizes these probability distributions to make this transparency explicit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PROBABILITY VISUALIZATION - Run this AFTER the main segmentation cell above\n",
    "# ============================================================================\n",
    "\n",
    "def run_segmentation_with_probabilities():\n",
    "    \"\"\"\n",
    "    Modified version of run_segmentation that returns class_scores\n",
    "    for probability visualization.\n",
    "    \"\"\"\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    image_name = os.path.splitext(os.path.basename(RGBA_IMAGE_PATH))[0]\n",
    "    \n",
    "    print(\"=== Loading images ===\")\n",
    "    img_rgba, normals = load_images(RGBA_IMAGE_PATH, NORMALS_IMAGE_PATH)\n",
    "    rgb = img_rgba[:, :, :3]\n",
    "    alpha = img_rgba[:, :, 3:]\n",
    "    \n",
    "    print(\"=== Creating overlapping windows ===\")\n",
    "    rgb_windows, positions = create_sliding_windows(rgb, WINDOW_SIZE, STRIDE)\n",
    "    alpha_windows, _ = create_sliding_windows(alpha, WINDOW_SIZE, STRIDE)\n",
    "    normals_windows, _ = create_sliding_windows(normals, WINDOW_SIZE, STRIDE)\n",
    "    print(f\"Created: {len(rgb_windows)} windows\")\n",
    "    \n",
    "    print(\"=== Loading model ===\")\n",
    "    model, n_classes = load_segmentation_model(MODEL_PATH, device)\n",
    "    print(f\"Model loaded: {n_classes} classes\")\n",
    "    \n",
    "    print(\"=== Performing segmentation ===\")\n",
    "    windows_data = []\n",
    "    with tqdm(total=len(rgb_windows), desc=\"Segmenting windows\") as pbar:\n",
    "        for i in range(len(rgb_windows)):\n",
    "            pred, probs = segment_window_with_probabilities(\n",
    "                model, rgb_windows[i], alpha_windows[i], normals_windows[i], device)\n",
    "            windows_data.append((pred, probs))\n",
    "            pbar.update(1)\n",
    "            if i % 10 == 0 and device == 'cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"=== Combining predictions ===\")\n",
    "    full_segmentation, class_scores = combine_predictions_center_weighted(\n",
    "        windows_data, positions, img_rgba.shape, n_classes)\n",
    "    \n",
    "    return full_segmentation, class_scores, rgb, normals, n_classes, image_name\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def visualize_pixel_probabilities(class_scores, x, y, class_names=CLASS_NAMES):\n",
    "    \"\"\"Show the probability distribution for a single pixel.\"\"\"\n",
    "    probs = class_scores[y, x, :]\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    colors = ['black', 'blue', 'red', 'gold'][:len(class_names)]\n",
    "    bars = ax.bar(class_names, probs * 100, color=colors, edgecolor='black')\n",
    "    ax.set_ylabel('Probability (%)', fontsize=12)\n",
    "    ax.set_xlabel('Masonry Class', fontsize=12)\n",
    "    ax.set_title(f'Class Probabilities at Pixel ({x}, {y})', fontsize=14)\n",
    "    ax.set_ylim(0, 100)\n",
    "    for bar, prob in zip(bars, probs):\n",
    "        ax.annotate(f'{prob*100:.1f}%', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
    "                    xytext=(0, 3), textcoords=\"offset points\", ha='center', fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return {name: f\"{prob*100:.1f}%\" for name, prob in zip(class_names, probs)}\n",
    "\n",
    "def create_probability_heatmaps(class_scores, class_names=CLASS_NAMES, save_path=None):\n",
    "    \"\"\"Create heatmaps showing probability for each class.\"\"\"\n",
    "    n_classes = min(class_scores.shape[2], len(class_names))\n",
    "    fig, axes = plt.subplots(1, n_classes, figsize=(4*n_classes, 4))\n",
    "    if n_classes == 1: axes = [axes]\n",
    "    for i, (ax, name) in enumerate(zip(axes, class_names[:n_classes])):\n",
    "        im = ax.imshow(class_scores[:, :, i], cmap='viridis', vmin=0, vmax=1)\n",
    "        ax.set_title(f'{name}\\nProbability', fontsize=12)\n",
    "        ax.axis('off')\n",
    "        plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    plt.suptitle('Per-Class Probability Maps', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved: {save_path}\")\n",
    "    plt.show()\n",
    "\n",
    "def create_uncertainty_map(class_scores, save_path=None):\n",
    "    \"\"\"Create confidence and uncertainty maps.\"\"\"\n",
    "    max_probs = np.max(class_scores, axis=2)\n",
    "    eps = 1e-10\n",
    "    entropy = -np.sum(class_scores * np.log(class_scores + eps), axis=2)\n",
    "    normalized_entropy = entropy / np.log(class_scores.shape[2])\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    im1 = axes[0].imshow(max_probs, cmap='RdYlGn', vmin=0.25, vmax=1.0)\n",
    "    axes[0].set_title('Prediction Confidence\\n(Max class probability)', fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "    plt.colorbar(im1, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    im2 = axes[1].imshow(normalized_entropy, cmap='hot', vmin=0, vmax=1)\n",
    "    axes[1].set_title('Classification Uncertainty\\n(Entropy)', fontsize=12)\n",
    "    axes[1].axis('off')\n",
    "    plt.colorbar(im2, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.suptitle('Probabilistic Uncertainty Analysis', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved: {save_path}\")\n",
    "    plt.show()\n",
    "    return max_probs, normalized_entropy\n",
    "\n",
    "def create_comparison_figure_for_paper(class_scores, segmentation, rgb_image,\n",
    "                                       sample_points=None, save_path=None):\n",
    "    \"\"\"Create comprehensive figure for paper - addresses reviewer comment.\"\"\"\n",
    "    if sample_points is None:\n",
    "        h, w = segmentation.shape\n",
    "        sample_points = [(w//4, h//4), (w//2, h//2), (3*w//4, 3*h//4)]\n",
    "    n_points = len(sample_points)\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    \n",
    "    # Top row: images\n",
    "    ax1 = fig.add_subplot(2, 3, 1)\n",
    "    rgb_display = cv2.cvtColor(rgb_image, cv2.COLOR_BGR2RGB)\n",
    "    ax1.imshow(rgb_display)\n",
    "    ax1.set_title('Original Orthomosaic', fontsize=12)\n",
    "    ax1.axis('off')\n",
    "    for i, (x, y) in enumerate(sample_points):\n",
    "        ax1.plot(x, y, 'wo', markersize=15, markeredgecolor='black', markeredgewidth=2)\n",
    "        ax1.annotate(f'{i+1}', (x, y), color='black', fontsize=10, ha='center', va='center', fontweight='bold')\n",
    "    \n",
    "    ax2 = fig.add_subplot(2, 3, 2)\n",
    "    colors_norm = np.array(CLASS_COLORS[:len(CLASS_NAMES)]) / 255.0\n",
    "    cmap_seg = ListedColormap(colors_norm)\n",
    "    ax2.imshow(segmentation, cmap=cmap_seg, vmin=0, vmax=len(CLASS_NAMES)-1)\n",
    "    ax2.set_title('Segmentation (argmax)', fontsize=12)\n",
    "    ax2.axis('off')\n",
    "    for i, (x, y) in enumerate(sample_points):\n",
    "        ax2.plot(x, y, 'wo', markersize=15, markeredgecolor='black', markeredgewidth=2)\n",
    "        ax2.annotate(f'{i+1}', (x, y), color='black', fontsize=10, ha='center', va='center', fontweight='bold')\n",
    "    \n",
    "    ax3 = fig.add_subplot(2, 3, 3)\n",
    "    max_probs = np.max(class_scores, axis=2)\n",
    "    im = ax3.imshow(max_probs, cmap='RdYlGn', vmin=0.25, vmax=1.0)\n",
    "    ax3.set_title('Prediction Confidence', fontsize=12)\n",
    "    ax3.axis('off')\n",
    "    plt.colorbar(im, ax=ax3, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # Bottom row: probability distributions\n",
    "    for i, (x, y) in enumerate(sample_points):\n",
    "        ax = fig.add_subplot(2, n_points, n_points + i + 1)\n",
    "        probs = class_scores[y, x, :]\n",
    "        predicted_class = np.argmax(probs)\n",
    "        colors = ['black', 'blue', 'red', 'gold'][:len(CLASS_NAMES)]\n",
    "        bars = ax.bar(range(len(CLASS_NAMES)), probs[:len(CLASS_NAMES)] * 100, color=colors, edgecolor='black')\n",
    "        if predicted_class < len(bars):\n",
    "            bars[predicted_class].set_edgecolor('lime')\n",
    "            bars[predicted_class].set_linewidth(3)\n",
    "        ax.set_ylabel('Probability (%)')\n",
    "        ax.set_xticks(range(len(CLASS_NAMES)))\n",
    "        ax.set_xticklabels(['BG', 'Ash', 'Poly', 'Qua'][:len(CLASS_NAMES)], fontsize=9)\n",
    "        ax.set_ylim(0, 100)\n",
    "        class_name = CLASS_NAMES[predicted_class] if predicted_class < len(CLASS_NAMES) else f'Class {predicted_class}'\n",
    "        ax.set_title(f'Point {i+1}: Predicted {class_name}', fontsize=10)\n",
    "        for bar, prob in zip(bars, probs[:len(CLASS_NAMES)]):\n",
    "            if prob > 0.05:\n",
    "                ax.annotate(f'{prob*100:.0f}%', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
    "                           xytext=(0, 2), textcoords=\"offset points\", ha='center', fontsize=8)\n",
    "    \n",
    "    plt.suptitle('Neural Network Probability Output vs. Binary Classification\\n'\n",
    "                 'Each pixel receives a probability distribution, not a single label',\n",
    "                 fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved: {save_path}\")\n",
    "    plt.show()\n",
    "\n",
    "def print_probability_statistics(class_scores, segmentation):\n",
    "    \"\"\"Print statistics for paper text.\"\"\"\n",
    "    max_probs = np.max(class_scores, axis=2)\n",
    "    non_bg_mask = segmentation > 0\n",
    "    print(\"=\" * 60)\n",
    "    print(\"PROBABILITY DISTRIBUTION STATISTICS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nManual classification: Always 100% confidence\")\n",
    "    print(\"Model output: Nuanced probability distributions\\n\")\n",
    "    print(f\"Overall - Mean confidence: {max_probs.mean()*100:.1f}%\")\n",
    "    print(f\"Overall - Median confidence: {np.median(max_probs)*100:.1f}%\")\n",
    "    if non_bg_mask.sum() > 0:\n",
    "        stone_probs = max_probs[non_bg_mask]\n",
    "        print(f\"\\nStone pixels - Mean confidence: {stone_probs.mean()*100:.1f}%\")\n",
    "        print(f\"Stone pixels - Min confidence: {stone_probs.min()*100:.1f}%\")\n",
    "    print(\"\\nConfidence distribution:\")\n",
    "    for thresh in [0.5, 0.7, 0.9, 0.95]:\n",
    "        pct = (max_probs >= thresh).sum() / max_probs.size * 100\n",
    "        print(f\"  Pixels >= {thresh*100:.0f}% confidence: {pct:.1f}%\")\n",
    "    print(\"\\nPer-class analysis:\")\n",
    "    for i, name in enumerate(CLASS_NAMES):\n",
    "        if i >= class_scores.shape[2]: break\n",
    "        class_mask = segmentation == i\n",
    "        if class_mask.sum() > 0:\n",
    "            class_probs = class_scores[class_mask, i]\n",
    "            print(f\"  {name}: {class_mask.sum():,} px, mean prob {class_probs.mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# RUN PROBABILITY ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Running segmentation with probability analysis...\")\n",
    "full_segmentation, class_scores, rgb, normals, n_classes, image_name = run_segmentation_with_probabilities()\n",
    "print(\"\\nSegmentation complete! Now generating probability visualizations...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SAMPLE POINT CONFIGURATION - Modify these for your image!\n",
    "# ============================================================================\n",
    "\n",
    "h, w = full_segmentation.shape\n",
    "SAMPLE_POINTS = [\n",
    "    (w // 4, h // 4),        # Top-left region\n",
    "    (w // 2, h // 2),        # Center\n",
    "    (3 * w // 4, 3 * h // 4) # Bottom-right region\n",
    "]\n",
    "\n",
    "# Or manually specify interesting points:\n",
    "# SAMPLE_POINTS = [(500, 300), (800, 600), (1200, 400)]\n",
    "\n",
    "print(f\"Sample points: {SAMPLE_POINTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 1. MAIN FIGURE FOR PAPER (addresses reviewer comment Line 417)\n",
    "# ============================================================================\n",
    "\n",
    "create_comparison_figure_for_paper(\n",
    "    class_scores, full_segmentation, rgb,\n",
    "    sample_points=SAMPLE_POINTS,\n",
    "    save_path=os.path.join(OUTPUT_DIR, f\"{image_name}_probability_comparison.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 2. STATISTICS FOR PAPER TEXT\n",
    "# ============================================================================\n",
    "\n",
    "print_probability_statistics(class_scores, full_segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 3. PER-CLASS PROBABILITY HEATMAPS\n",
    "# ============================================================================\n",
    "\n",
    "create_probability_heatmaps(\n",
    "    class_scores,\n",
    "    save_path=os.path.join(OUTPUT_DIR, f\"{image_name}_class_probability_heatmaps.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 4. UNCERTAINTY/CONFIDENCE MAPS\n",
    "# ============================================================================\n",
    "\n",
    "max_probs, uncertainty = create_uncertainty_map(\n",
    "    class_scores,\n",
    "    save_path=os.path.join(OUTPUT_DIR, f\"{image_name}_uncertainty_map.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 5. INTERACTIVE: Explore probability at any pixel\n",
    "# ============================================================================\n",
    "\n",
    "x, y = 500, 300  # <-- MODIFY THESE COORDINATES\n",
    "\n",
    "print(f\"Pixel ({x}, {y}): Predicted class = {CLASS_NAMES[full_segmentation[y, x]]}\")\n",
    "visualize_pixel_probabilities(class_scores, x, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
